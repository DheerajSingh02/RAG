{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11585286,"sourceType":"datasetVersion","datasetId":7264039}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"name":"RAG-Using-LangChain","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/dheerajetx/rag-using-langchain.58dbbe2d-9e58-4715-b5b6-a5dbed14b068.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20250427/auto/storage/goog4_request&X-Goog-Date=20250427T140231Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=5aa0a920ead9ef6a4c7521c895d6fbf8072fda4439422da77aa665a9d3f02b860709fc60487fec2a25538903f1d85529164f5ccc699d6d35fb28b7f4479b60f1c3807fc92834867c3dd96c2b195e3f77e4de5b30af79000657d876e3faf0cae5a09f9b0aa573a316186a0501fe0049c1cc43564154eb3cba1298b63e1a961e3fff05a73dc90a782f960f52124ac82a7d02ed737f97a32e889b46efa61f9a7a8fbaac42f9977e5c67a526f44f4a61953b2bc113c82f94722994a34ff494a522c549ae5476f7e6da0a9673e8af5bd214fdf3cb18bf2093649620c1d7d9693d37383265ede61d670b7ccba4d23c0c3c620b4a9dd5f44bc0484313932e821eff70f1","timestamp":1745769875708}]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# !pip uninstall -y langchain langchain_openai langchain_community langchain_core numpy tensorflow\n","# !pip install --quiet -U openai pypdf chromadb\n","# !pip install --quiet  -U langchain-community langchain-openai langchain numpy numba"],"metadata":{"id":"vN_MwCej760V","executionInfo":{"status":"ok","timestamp":1745769444550,"user_tz":-330,"elapsed":12,"user":{"displayName":"","userId":""}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Import required libraries after ensuring they're installed properly\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n","from langchain_community.vectorstores import Chroma\n","from langchain.chains import create_retrieval_chain\n","from langchain.chains.combine_documents import create_stuff_documents_chain\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.memory import ConversationBufferMemory"],"metadata":{"trusted":true,"id":"VHJChdbQjpYQ","executionInfo":{"status":"ok","timestamp":1745769515603,"user_tz":-330,"elapsed":6,"user":{"displayName":"","userId":""}}},"outputs":[],"execution_count":6},{"cell_type":"code","source":["# from google.colab import userdata\n","# # Set OpenAI API key from Colab secrets\n","# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"],"metadata":{"trusted":true,"id":"mLhIS30FjpYR","executionInfo":{"status":"ok","timestamp":1745769542466,"user_tz":-330,"elapsed":3,"user":{"displayName":"","userId":""}}},"outputs":[],"execution_count":8},{"cell_type":"code","source":["def load_and_process_document(pdf_path):\n","    \"\"\"\n","    Load and process PDF document with metadata\n","\n","    Args:\n","        pdf_path (str): Path to the PDF file\n","\n","    Returns:\n","        list: List of document chunks\n","    \"\"\"\n","    # Load PDF\n","    loader = PyPDFLoader(pdf_path)\n","    documents = loader.load()\n","\n","    # Add metadata to each page\n","    for i, doc in enumerate(documents):\n","        doc.metadata = {\n","            \"source\": pdf_path,\n","            \"page\": i + 1,\n","            \"document_type\": \"pdf\"\n","        }\n","\n","    # Split documents into manageable chunks\n","    text_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=1000,\n","        chunk_overlap=200,\n","        length_function=len,\n","        add_start_index=True\n","    )\n","    chunks = text_splitter.split_documents(documents)\n","\n","    return chunks"],"metadata":{"id":"5meeEDxy-e1l","executionInfo":{"status":"ok","timestamp":1745769593366,"user_tz":-330,"elapsed":43,"user":{"displayName":"","userId":""}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def create_qa_system(chunks):\n","    \"\"\"\n","    Create a QA system using OpenAI models\n","\n","    Args:\n","        chunks: Document chunks\n","\n","    Returns:\n","        retrieval_chain: Chain for answering questions\n","        memory: Conversation memory\n","    \"\"\"\n","    # Initialize embeddings\n","    embeddings = OpenAIEmbeddings()\n","\n","    # Create vector store\n","    vector_store = Chroma.from_documents(\n","        documents=chunks,\n","        embedding=embeddings\n","    )\n","\n","    # Create retriever\n","    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n","\n","    # Initialize language model\n","    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n","\n","    # Create prompt template\n","    prompt = ChatPromptTemplate.from_template(\"\"\"\n","    You are a helpful assistant that answers questions based on provided documents.\n","\n","    Context information from documents:\n","    {context}\n","\n","    Answer the following question based only on the provided context:\n","    {input}\n","\n","    If the answer cannot be found in the context, say \"I don't have enough information to answer this question.\"\n","    \"\"\")\n","\n","    # Create document chain\n","    document_chain = create_stuff_documents_chain(llm, prompt)\n","\n","    # Create retrieval chain\n","    retrieval_chain = create_retrieval_chain(retriever, document_chain)\n","\n","    # Create memory for tracking conversation history\n","    memory = ConversationBufferMemory()\n","\n","    return retrieval_chain, memory\n"],"metadata":{"id":"7ig7kpf9-hI0","executionInfo":{"status":"ok","timestamp":1745769762912,"user_tz":-330,"elapsed":44,"user":{"displayName":"","userId":""}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def main():\n","    \"\"\"Main function to orchestrate the PDF QA system\"\"\"\n","    print(\"=\" * 50)\n","    print(\"PDF Question Answering System using OpenAI\")\n","    print(\"=\" * 50)\n","\n","    # Upload PDF in Colab\n","    print(\"\\nPlease upload a PDF file:\")\n","    uploaded = files.upload()\n","\n","    if not uploaded:\n","        print(\"No file uploaded. Exiting.\")\n","        return\n","\n","    pdf_path = list(uploaded.keys())[0]  # Get the uploaded PDF's filename\n","\n","    # Process document\n","    print(\"\\nProcessing document...\")\n","    chunks = load_and_process_document(pdf_path)\n","    print(f\"Document processed into {len(chunks)} chunks.\")\n","\n","    # Create QA system\n","    print(\"\\nSetting up QA system...\")\n","    qa_chain, memory = create_qa_system(chunks)\n","    print(\"QA system ready!\")\n","\n","    # Example interaction loop\n","    print(\"\\n\" + \"=\" * 50)\n","    print(\"You can now ask questions about the document.\")\n","    print(\"Type 'quit' to exit.\")\n","    print(\"=\" * 50)\n","\n","    chat_history = []\n","\n","    while True:\n","        question = input(\"\\nYour question: \")\n","        if question.lower() in ['quit', 'exit', 'bye']:\n","            print(\"\\nThank you for using the PDF QA system. Goodbye!\")\n","            break\n","\n","        try:\n","            # Process question and get response\n","            response = qa_chain.invoke({\"input\": question})\n","            answer = response[\"answer\"]\n","            print(\"\\nAnswer:\", answer)\n","\n","            # Update conversation history\n","            chat_history.append((question, answer))\n","            memory.save_context({\"input\": question}, {\"output\": answer})\n","\n","        except Exception as e:\n","            print(f\"\\nError: {e}\")\n","            print(\"Please try rephrasing your question or check your API key.\")\n"],"metadata":{"id":"LdEptm8o_QWN","executionInfo":{"status":"ok","timestamp":1745769794478,"user_tz":-330,"elapsed":9,"user":{"displayName":"","userId":""}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    main()"],"metadata":{"id":"_vabnaA5_g_f"},"execution_count":null,"outputs":[]}]}